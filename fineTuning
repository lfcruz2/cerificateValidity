import pandas as pd
import json
import ollama  # Make sure to `pip install ollama`
import subprocess
from sklearn.model_selection import train_test_split

# -------------------------
# Configuration Parameters
# -------------------------
DATA_FILE = 'classified_data.csv'          # CSV file with classified trade data
TRAIN_DATA_FILE = 'training_data.json'       # JSON file for training data (with embeddings)
EVAL_DATA_FILE = 'evaluation_data.json'      # JSON file for evaluation data (without pair_id)
EVAL_RESULTS_FILE = 'evaluation_results.csv'  # CSV file to store evaluation results

ORIG_MODEL = 'gemma-3'                       # Original model name (before fine-tuning)
FT_MODEL = 'gemma-3-ft'                      # Fine-tuned model name (with "ft" suffix)
EMBEDDING_MODEL = 'all-minilm:l6-v2'         # Embedding model pulled via Ollama

# Specify which columns to include when creating the text representation.
# For training we include 'pair_id' so the model learns the relationship.
# (Assume the CSV has a column 'replacement_trade_id' for the expected replacement.)
EMBEDDING_COLUMNS = ['column1', 'column2', 'column3', 'pair_id', 'replacement_trade_id']
# The trade ID column (stored separately for reference)
TRADE_ID_COLUMN = 'trade_id'

# For evaluation, exclude the pair_id so that the model must rely on the remaining fields.
EVAL_EMBEDDING_COLUMNS = [col for col in EMBEDDING_COLUMNS if col != 'pair_id']

# -------------------------
# Helper Functions
# -------------------------
def preprocess_row(row, columns_to_include=None):
    """
    Convert a row into a text representation by concatenating each column name and its value.
    If columns_to_include is provided, only include those columns.
    """
    parts = []
    if columns_to_include:
        for col in columns_to_include:
            if col in row:
                parts.append(f"{col}: {row[col]}")
    else:
        for col, value in row.items():
            parts.append(f"{col}: {value}")
    return "\n".join(parts)

def get_embedding_via_ollama(text):
    """
    Generate an embedding for the given text using the Ollama embed API.
    Calls: ollama.embed(model=EMBEDDING_MODEL, input=text)
    Expects the response to be a dict with a key "embedding".
    """
    try:
        response = ollama.embed(model=EMBEDDING_MODEL, input=text)
        embedding = response.get("embedding")
        if embedding is None:
            print("Warning: 'embedding' key not found in the response. Using raw response.")
            embedding = response
        return embedding
    except Exception as e:
        print("Error during embedding generation:", e)
        return None

def prepare_data(df, columns_to_include, trade_id_column):
    """
    For each record in the DataFrame, generate a text representation using the specified columns,
    compute its embedding via the Ollama embed API, and return a list of dictionaries.
    Each dictionary includes:
      - The original data.
      - 'text_representation': the combined text.
      - 'embedding': the computed embedding.
      - 'trade_id': the unique trade identifier.
    """
    records = []
    for _, row in df.iterrows():
        text_repr = preprocess_row(row, columns_to_include=columns_to_include)
        embedding = get_embedding_via_ollama(text_repr)
        record = row.to_dict()
        record['text_representation'] = text_repr
        record['embedding'] = embedding
        record['trade_id'] = record.get(trade_id_column)
        records.append(record)
    return records

def download_model(model_name):
    """
    Ensure the specified model is available by pulling it with Ollama.
    """
    try:
        print(f"Pulling model '{model_name}' using Ollama...")
        ollama.pull(model_name)
        print(f"Model '{model_name}' is available.")
    except Exception as e:
        print(f"Error pulling model '{model_name}':", e)

def fine_tune_model(original_model, training_data_file, fine_tuned_model):
    """
    Fine-tune the original model using the training data.
    We use a subprocess call to execute:
      ollama fine-tune <original_model> --data <training_data_file> --output <fine_tuned_model>
    """
    try:
        print(f"Initiating fine-tuning for model '{original_model}' with training data from '{training_data_file}', output model: '{fine_tuned_model}'...")
        subprocess.run(["ollama", "fine-tune", original_model, "--data", training_data_file, "--output", fine_tuned_model], check=True)
        print("Fine-tuning initiated successfully.")
    except Exception as e:
        print("Error during fine-tuning:", e)

def query_model(prompt, model_name):
    """
    Query the specified model using the Ollama chat API.
    Constructs a chat message with the prompt and expects the model's response in JSON format.
    """
    try:
        response = ollama.chat(
            model=model_name,
            messages=[{'role': 'user', 'content': prompt}]
        )
        # Extract the content from the response message.
        text = response.message.content
        try:
            data = json.loads(text)
            return data
        except json.JSONDecodeError:
            # If the response is not valid JSON, return the raw text.
            return text.strip()
    except Exception as e:
        print("Error querying the model:", e)
        return None

def evaluate_model(evaluation_records, model_name, results_file):
    """
    Iterate over all evaluation records, query the fine-tuned model, and record:
      - trade_id
      - expected replacement_trade_id (from the evaluation record)
      - predicted replacement_transaction (from model's response)
      - explanation (from model's response)
      - a correctness flag (1 if prediction matches expected, else 0)
    Save all results to a CSV file and print overall accuracy.
    """
    results = []
    correct_count = 0
    total = len(evaluation_records)
    
    for record in evaluation_records:
        prompt = (
            "Below is the data for a canceled trade (without the pair id):\n"
            f"{record['text_representation']}\n\n"
            "Based on this information, predict the replacement trade and provide a detailed explanation of your reasoning. "
            "Output your answer in JSON format with keys 'replacement_transaction' and 'explanation'."
        )
        response = query_model(prompt, model_name)
        
        predicted = ""
        explanation = ""
        if isinstance(response, dict):
            predicted = response.get("replacement_transaction", "").strip()
            explanation = response.get("explanation", "").strip()
        else:
            predicted = str(response)
        
        expected = str(record.get("replacement_trade_id", "")).strip()
        correct = 1 if predicted == expected else 0
        correct_count += correct
        
        results.append({
            "trade_id": record.get("trade_id", ""),
            "expected_replacement_trade": expected,
            "predicted_replacement_trade": predicted,
            "explanation": explanation,
            "correct": correct
        })
        print(f"Evaluated trade {record.get('trade_id', '')}: Expected '{expected}' | Predicted '{predicted}' | Correct: {correct}")
    
    accuracy = (correct_count / total) * 100 if total > 0 else 0
    print(f"\nOverall Evaluation Accuracy: {accuracy:.2f}% ({correct_count}/{total})")
    
    results_df = pd.DataFrame(results)
    results_df.to_csv(results_file, index=False)
    print(f"Evaluation results saved to {results_file}")

# -------------------------
# Main Workflow
# -------------------------
if __name__ == '__main__':
    # Step 1: Load the classified CSV data
    print("Loading CSV data...")
    df = pd.read_csv(DATA_FILE)
    print(f"Loaded {len(df)} records from {DATA_FILE}.")

    # Step 2: Split the data into training and evaluation sets (80% training, 20% evaluation)
    train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)
    print(f"Training set: {len(train_df)} records; Evaluation set: {len(eval_df)} records.")

    # Step 3a: Prepare the training data (include all fields, including pair_id)
    print("Preparing training data (including pair_id)...")
    training_records = prepare_data(train_df, columns_to_include=EMBEDDING_COLUMNS, trade_id_column=TRADE_ID_COLUMN)
    with open(TRAIN_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(training_records, f, ensure_ascii=False, indent=2)
    print(f"Training data saved to {TRAIN_DATA_FILE}.")

    # Step 3b: Prepare the evaluation data (exclude pair_id so the model must rely on other fields)
    print("Preparing evaluation data (excluding pair_id)...")
    evaluation_records = prepare_data(eval_df, columns_to_include=EVAL_EMBEDDING_COLUMNS, trade_id_column=TRADE_ID_COLUMN)
    with open(EVAL_DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(evaluation_records, f, ensure_ascii=False, indent=2)
    print(f"Evaluation data saved to {EVAL_DATA_FILE}.")

    # Step 4: Ensure the original model is available by pulling it
    download_model(ORIG_MODEL)

    # Step 5: Fine-tune the original model using the training data, producing a new fine-tuned model (FT_MODEL)
    fine_tune_model(ORIG_MODEL, TRAIN_DATA_FILE, FT_MODEL)

    # Step 6: Evaluate the fine-tuned model on all evaluation records and save the detailed results
    print("Evaluating the fine-tuned model on the evaluation dataset...")
    evaluate_model(evaluation_records, FT_MODEL, EVAL_RESULTS_FILE)
